{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import timeit as tm\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data dimensions: (295169, 63)\n",
      "training label dimensions: (295169, 6)\n"
     ]
    }
   ],
   "source": [
    "# Open training data to pandas\n",
    "train_dat_pandas = pd.read_csv('../data/clean_data/train_vectors.csv', index_col=0, encoding='utf-8')\n",
    "del train_dat_pandas['TYPE']\n",
    "\n",
    "# Open training labels to pandas\n",
    "train_lbl_pandas = pd.read_csv('../data/clean_data/train_labels.csv', index_col=0, encoding='utf-8')\n",
    "del train_lbl_pandas['YEAR']\n",
    "\n",
    "# Save headers\n",
    "headers = [list(train_dat_pandas)]\n",
    "\n",
    "# Convert pandas to numpy matrix\n",
    "train_dat = train_dat_pandas.as_matrix()\n",
    "print 'training data dimensions:', train_dat.shape\n",
    "\n",
    "# Convert pandas to numpy matrix\n",
    "train_lbl = train_lbl_pandas.as_matrix()\n",
    "print 'training label dimensions:', train_lbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data dimensions: (34142, 63)\n",
      "testing label dimensions: (34142, 6)\n"
     ]
    }
   ],
   "source": [
    "# Open test data\n",
    "test_dat_pandas = pd.read_csv('../data/clean_data/test_vectors.csv', index_col=0, encoding='utf-8')\n",
    "del test_dat_pandas['TYPE']\n",
    "\n",
    "# Open test labels\n",
    "test_lbl_pandas = pd.read_csv('../data/clean_data/test_labels.csv', index_col=0, encoding='utf-8')\n",
    "del test_lbl_pandas['YEAR']\n",
    "\n",
    "# Convert pandas to numpy matrix\n",
    "test_dat = test_dat_pandas.as_matrix()\n",
    "print 'testing data dimensions:', test_dat.shape\n",
    "\n",
    "# Convert pandas to numpy matrix\n",
    "test_lbl = test_lbl_pandas.as_matrix()\n",
    "print 'testing label dimensions:', test_lbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating test and train for final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dat_pandas = pd.concat([train_dat_pandas, test_dat_pandas])\n",
    "full_dat = full_dat_pandas.as_matrix()\n",
    "\n",
    "full_lbl_pandas = pd.concat([train_lbl_pandas, test_lbl_pandas])\n",
    "full_lbl = full_lbl_pandas.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting one hot labels to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 ..., 4 2 3] [4 2 2 ..., 4 2 2] [[0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " ..., \n",
      " [0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# method to convert a one hot encoding array into a numeric array\n",
    "def onehot_2_numeric(onehot):\n",
    "    numeric = []\n",
    "    for elem in onehot:\n",
    "        result = 0\n",
    "        for i, k in enumerate(elem):\n",
    "            result += i * k\n",
    "        numeric.append(result)\n",
    "    return np.asarray(numeric)\n",
    "\n",
    "\n",
    "train_lbl_txt = onehot_2_numeric(train_lbl)\n",
    "test_lbl_txt = onehot_2_numeric(test_lbl)\n",
    "full_lbl_txt = onehot_2_numeric(full_lbl)\n",
    "print train_lbl_txt, test_lbl_txt, full_lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.43707687, -0.46160515,  0.88683494, ...,  0.25718323,\n",
       "         0.46704734, -0.77932334],\n",
       "       [-1.43707687, -0.46160515,  0.88683494, ...,  0.25718323,\n",
       "         0.46704734, -0.77932334],\n",
       "       [-1.43707687, -0.16683183,  0.88683494, ...,  1.03117731,\n",
       "         1.0494166 , -0.51868547],\n",
       "       ..., \n",
       "       [ 1.57106923, -1.05115178,  0.07267337, ..., -0.45880567,\n",
       "        -0.35490798,  0.78072654],\n",
       "       [ 1.57106923,  0.42271481, -1.80602055, ...,  1.46893604,\n",
       "         1.48036877, -0.50420559],\n",
       "       [ 1.57106923, -1.05115178,  0.79614277, ..., -0.45880567,\n",
       "        -0.35490798,  0.78072654]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature vector scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_dat)\n",
    "train_dat = scaler.transform(train_dat)\n",
    "test_dat = scaler.transform(test_dat)\n",
    "\n",
    "scaler.fit_transform(full_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components='mle')\n",
    "# print pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pca.fit(train_dat)\n",
    "# print train_dat.shape\n",
    "# train_dat = pca.transform(train_dat)\n",
    "# print train_dat.shape\n",
    "\n",
    "# print test_dat.shape\n",
    "# test_dat = pca.transform(test_dat)\n",
    "# print test_dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit Linear Regression\n",
    "lin_reg = LinearRegression(n_jobs=-1, normalize=True)\n",
    "lin_reg.fit(train_dat, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = lin_reg.predict(test_dat)\n",
    "print predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute RMSE\n",
    "\n",
    "import math\n",
    "\n",
    "errors = []\n",
    "\n",
    "# compute squared errors\n",
    "for i in xrange(predictions.shape[0]):\n",
    "    p = predictions[i]\n",
    "    t = test_lbl[i]\n",
    "    \n",
    "    # compute distance\n",
    "    squared_distance = 0.0\n",
    "    for j in xrange(predictions.shape[1]):\n",
    "        squared_distance += (p[j] - t[j])**2\n",
    "    \n",
    "    errors.append(squared_distance)\n",
    "\n",
    "rmse = math.sqrt(sum(errors)/len(errors))\n",
    "print 'Root mean squared error:', rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lin_reg, '../models/linear_regression_model.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression(n_jobs=-1)\n",
    "# clf.fit(train_dat, train_lbl_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions = clf.predict(test_dat)\n",
    "# p_predictions = clf.predict_proba(test_dat)\n",
    "\n",
    "# print 'predictions dimensions:', predictions.shape\n",
    "# print 'probabilities per class:', p_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Table of probabilities for each class\n",
    "# for i in range(6):\n",
    "#     print str(i)+'\\t',\n",
    "\n",
    "# print ''\n",
    "\n",
    "# for i in xrange(len(p_predictions)):\n",
    "    \n",
    "#     for j in xrange(len(p_predictions[i])):\n",
    "#         print(\"%.2f\" % (p_predictions[i][j]*100))+'%\\t',\n",
    "    \n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(test_lbl_txt, predictions)\n",
    "# print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "folder = StratifiedKFold(train_lbl_txt, n_folds=5, shuffle=False)\n",
    "\n",
    "clf = LogisticRegressionCV(n_jobs=-1, solver='liblinear', cv=folder, verbose=5)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(train_dat, train_lbl_txt)\n",
    "print clf.score(test_dat, test_lbl_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, '../models/logistic_regression_model.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(train_dat, train_lbl_txt)\n",
    "predictions = clf.predict(test_dat)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_lbl_txt, predictions)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "folder = StratifiedKFold(train_lbl_txt, n_folds=5, shuffle=False)\n",
    "parameters = {'max_depth':[None, 2, 4, 8, 16, 32, 64]}\n",
    "dtc_clf = DecisionTreeClassifier()\n",
    "\n",
    "clf = GridSearchCV(dtc_clf, parameters, n_jobs=-1, pre_dispatch='n_jobs', cv=folder, refit=True, verbose=5)\n",
    "clf.fit(train_dat, train_lbl_txt)\n",
    "\n",
    "print 'Score on test data:', clf.score(test_dat, test_lbl_txt)\n",
    "\n",
    "print 'best params:', clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, '../models/decision_tree_model.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate k-fold split in the training data\n",
    "kf = StratifiedKFold(train_lbl_txt, n_folds=5, shuffle=True)\n",
    "\n",
    "# Do multiple runs and save'em to runs list\n",
    "runs = []\n",
    "depths = [None, 2, 4, 8, 16, 32, 64]\n",
    "\n",
    "print 'this will take a while...',\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d)\n",
    "    for t,v in kf:\n",
    "        trn = train_dat[t]\n",
    "        val = train_dat[v]\n",
    "        trn_lbl = train_lbl_txt[t]\n",
    "        val_lbl = train_lbl_txt[v]\n",
    "        clf.fit(trn, trn_lbl)\n",
    "        predictions = clf.predict(val)\n",
    "        #score = accuracy_score(val_lbl, predictions)\n",
    "        score = clf.score(val, val_lbl)\n",
    "        runs.append(tuple([d, score]))\n",
    "        print d, score\n",
    "print 'done!'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_result = max(runs, key=lambda run: run[1])\n",
    "print 'Best result:', best_result\n",
    "best_d = best_result[0]\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=best_d)\n",
    "clf.fit(train_dat, train_lbl_txt)\n",
    "print 'Score on test data:', clf.score(test_dat, test_lbl_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49753968718879971"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "clf.fit(train_dat, train_lbl_txt)\n",
    "clf.score(test_dat, test_lbl_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation on random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this will take a while...\n",
      "run: None auto gini done!\n",
      "run: None auto entropy done!\n",
      "run: None log2 gini done!\n",
      "run: None log2 entropy done!\n",
      "run: None None gini done!\n",
      "run: None None entropy done!\n",
      "run: 2 auto gini done!\n",
      "run: 2 auto entropy done!\n",
      "run: 2 log2 gini done!\n",
      "run: 2 log2 entropy done!\n",
      "run: 2 None gini done!\n",
      "run: 2 None entropy done!\n",
      "run: 4 auto gini done!\n",
      "run: 4 auto entropy done!\n",
      "run: 4 log2 gini done!\n",
      "run: 4 log2 entropy done!\n",
      "run: 4 None gini done!\n",
      "run: 4 None entropy done!\n",
      "run: 8 auto gini done!\n",
      "run: 8 auto entropy done!\n",
      "run: 8 log2 gini done!\n",
      "run: 8 log2 entropy done!\n",
      "run: 8 None gini done!\n",
      "run: 8 None entropy done!\n",
      "run: 16 auto gini done!\n",
      "run: 16 auto entropy done!\n",
      "run: 16 log2 gini done!\n",
      "run: 16 log2 entropy done!\n",
      "run: 16 None gini done!\n",
      "run: 16 None entropy done!\n",
      "run: 32 auto gini done!\n",
      "run: 32 auto entropy done!\n",
      "run: 32 log2 gini done!\n",
      "run: 32 log2 entropy done!\n",
      "run: 32 None gini done!\n",
      "run: 32 None entropy done!\n",
      "run: 64 auto gini done!\n",
      "run: 64 auto entropy done!\n",
      "run: 64 log2 gini done!\n",
      "run: 64 log2 entropy done!\n",
      "run: 64 None gini done!\n",
      "run: 64 None entropy done!\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "# Generate k-fold split in the training data\n",
    "kf = StratifiedKFold(train_lbl_txt, n_folds=5, shuffle=True)\n",
    "\n",
    "# Do multiple runs and save'em to runs list\n",
    "runs = []\n",
    "params = []\n",
    "\n",
    "depths = [None, 2, 4, 8, 16, 32, 64]\n",
    "max_features = ['auto', 'log2', None]\n",
    "criterions = ['gini', 'entropy']\n",
    "for d in depths:\n",
    "    for mf in max_features:\n",
    "        for c in criterions:\n",
    "            params.append([d, mf, c])\n",
    "\n",
    "\n",
    "print 'this will take a while...'\n",
    "for d, mf, c in params:\n",
    "    clf = RandomForestClassifier(n_jobs=-1, max_depth=d, max_features=mf, criterion=c)\n",
    "    print 'run:', d, mf, c,\n",
    "    for t,v in kf:\n",
    "        trn = train_dat[t]\n",
    "        val = train_dat[v]\n",
    "        trn_lbl = train_lbl_txt[t]\n",
    "        val_lbl = train_lbl_txt[v]\n",
    "        clf.fit(trn, trn_lbl)\n",
    "        score = clf.score(val, val_lbl)\n",
    "        runs.append([score, d, mf, c])\n",
    "    print 'done!'\n",
    "print 'All done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/random_forest_model.p',\n",
       " '../models/random_forest_model.p_01.npy',\n",
       " '../models/random_forest_model.p_02.npy',\n",
       " '../models/random_forest_model.p_03.npy',\n",
       " '../models/random_forest_model.p_04.npy',\n",
       " '../models/random_forest_model.p_05.npy',\n",
       " '../models/random_forest_model.p_06.npy',\n",
       " '../models/random_forest_model.p_07.npy',\n",
       " '../models/random_forest_model.p_08.npy',\n",
       " '../models/random_forest_model.p_09.npy',\n",
       " '../models/random_forest_model.p_10.npy',\n",
       " '../models/random_forest_model.p_11.npy',\n",
       " '../models/random_forest_model.p_12.npy',\n",
       " '../models/random_forest_model.p_13.npy',\n",
       " '../models/random_forest_model.p_14.npy',\n",
       " '../models/random_forest_model.p_15.npy',\n",
       " '../models/random_forest_model.p_16.npy',\n",
       " '../models/random_forest_model.p_17.npy',\n",
       " '../models/random_forest_model.p_18.npy',\n",
       " '../models/random_forest_model.p_19.npy',\n",
       " '../models/random_forest_model.p_20.npy',\n",
       " '../models/random_forest_model.p_21.npy',\n",
       " '../models/random_forest_model.p_22.npy',\n",
       " '../models/random_forest_model.p_23.npy',\n",
       " '../models/random_forest_model.p_24.npy',\n",
       " '../models/random_forest_model.p_25.npy',\n",
       " '../models/random_forest_model.p_26.npy',\n",
       " '../models/random_forest_model.p_27.npy',\n",
       " '../models/random_forest_model.p_28.npy',\n",
       " '../models/random_forest_model.p_29.npy',\n",
       " '../models/random_forest_model.p_30.npy',\n",
       " '../models/random_forest_model.p_31.npy',\n",
       " '../models/random_forest_model.p_32.npy',\n",
       " '../models/random_forest_model.p_33.npy',\n",
       " '../models/random_forest_model.p_34.npy',\n",
       " '../models/random_forest_model.p_35.npy',\n",
       " '../models/random_forest_model.p_36.npy',\n",
       " '../models/random_forest_model.p_37.npy',\n",
       " '../models/random_forest_model.p_38.npy',\n",
       " '../models/random_forest_model.p_39.npy',\n",
       " '../models/random_forest_model.p_40.npy',\n",
       " '../models/random_forest_model.p_41.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champion = max(runs, key=lambda run: run[0])\n",
    "score, d, mf, c = champion\n",
    "clf = RandomForestClassifier(n_jobs=-1, max_depth=d, max_features=mf, criterion=c)\n",
    "clf.fit(full_dat, full_lbl_txt)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, '../models/random_forest_model.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "# folder = StratifiedKFold(train_lbl_txt, n_folds=5, shuffle=False)\n",
    "\n",
    "# parameters = {'kernel':['linear', 'poly', 'rbf'], 'C':[64, 32, 16, 8], 'probability':[False], 'max_iter':[1000]}\n",
    "# svm_clf = SVC()\n",
    "\n",
    "# clf = GridSearchCV(svm_clf, parameters, n_jobs=-1, pre_dispatch='n_jobs', cv=folder, refit=True, verbose=5)\n",
    "# clf.fit(train_dat_scaled, train_lbl_txt)\n",
    "# clf.score(test_dat_scaled, test_lbl_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print 'best score:', clf.best_score_\n",
    "# print 'best params:', clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
